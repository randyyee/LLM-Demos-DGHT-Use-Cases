{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo #3 Using LLM to assist with submission grading tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo shows how you can use LLMs to help perform a grading task with a rubic. The example uses an established SIB data management rubric to assess SIB submissions involving data mangement.\n",
    "\n",
    "In this demo, we'll set up an army of agents tasked with assessing data management standards for research protocols. We will setup individual agents to evaulate each criteria and a final grader agent to consolidate all the results from each agent to make a recommendation on the submission.The criteria comes from SIB's \"Research Protocol Data Management Review Guidelines.\"\n",
    "\n",
    "As with all AI-assisted tasks, a human being should still have final say. Though this system may be implemented before the human reviewer step ensure higher quality submissions being reviewed and potentially reducing the number of rounds of review thereby speeding the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your notebook as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import DOCXSearchTool\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_VERSION\"] = os.environ.get(\"AZURE_OPENAI_VERSION\")\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ.get(\"AZURE_OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_llm = AzureChatOpenAI(\n",
    "    api_version=os.environ[\"AZURE_OPENAI_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the tool's config to use Azure models then initialize the DOCXSearchTool...\\\n",
    "\\\n",
    "<i>DOCXSearchTool is a RAG tool designed for semantic searching within DOCX documents. It enables users to effectively search and extract relevant information from DOCX files using query-based searches. This tool is invaluable for data analysis, information management, and research tasks, streamlining the process of finding specific information within large document collections (https://docs.crewai.com/tools/DOCXSearchTool/)<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "Key 'llm' error:\nAzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f66a7b0ea40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f66a7b40c10>, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://edav-openai-pilot-east2.openai.azure.com/', deployment_name='edav-chatapp-share-gpt4-32k-tpm25kplus-v0613-dfilter', openai_api_version='2023-05-15', openai_api_type='azure') should be instance of 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaUnexpectedTypeError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/schema.py:405\u001b[0m, in \u001b[0;36mSchema.validate\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     nvalue \u001b[39m=\u001b[39m Schema(svalue, error\u001b[39m=\u001b[39;49me, ignore_extra_keys\u001b[39m=\u001b[39;49mi)\u001b[39m.\u001b[39;49mvalidate(value, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[39mexcept\u001b[39;00m SchemaError \u001b[39mas\u001b[39;00m x:\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/schema.py:369\u001b[0m, in \u001b[0;36mSchema.validate\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m exitstack \u001b[39m=\u001b[39m ExitStack()\n\u001b[0;32m--> 369\u001b[0m data \u001b[39m=\u001b[39m Schema(\u001b[39mdict\u001b[39;49m, error\u001b[39m=\u001b[39;49me)\u001b[39m.\u001b[39;49mvalidate(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    370\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)()  \u001b[39m# new - is a dict of the validated values\u001b[39;00m\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/schema.py:440\u001b[0m, in \u001b[0;36mSchema.validate\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m         message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepend_schema_name(message)\n\u001b[0;32m--> 440\u001b[0m         \u001b[39mraise\u001b[39;00m SchemaUnexpectedTypeError(message, e\u001b[39m.\u001b[39mformat(data) \u001b[39mif\u001b[39;00m e \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m flavor \u001b[39m==\u001b[39m VALIDATOR:\n",
      "\u001b[0;31mSchemaUnexpectedTypeError\u001b[0m: AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f66a7b0ea40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f66a7b40c10>, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://edav-openai-pilot-east2.openai.azure.com/', deployment_name='edav-chatapp-share-gpt4-32k-tpm25kplus-v0613-dfilter', openai_api_version='2023-05-15', openai_api_type='azure') should be instance of 'dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m submission_tool \u001b[39m=\u001b[39m DOCXSearchTool(\n\u001b[1;32m      2\u001b[0m     config\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m      3\u001b[0m         llm\u001b[39m=\u001b[39;49mazure_llm,\n\u001b[1;32m      4\u001b[0m         embedder\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m      5\u001b[0m             provider\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mazure_openai\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m# or openai, ollama, ...\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m             config\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m      7\u001b[0m                 model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-embedding-ada-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m                 \u001b[39m#task_type=\"retrieval_document\",\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m                 \u001b[39m# title=\"Embeddings\",\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m             ),\n\u001b[1;32m     11\u001b[0m         ),\n\u001b[1;32m     12\u001b[0m     ),\n\u001b[1;32m     13\u001b[0m     docx\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresources/Nigeria HIV CBS Protocol_v3.4_27062022_PHIS3_clean.docx\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[39m#submission = submission_tool(docx='resources/Nigeria HIV CBS Protocol_v3.4_27062022_PHIS3_clean.docx')\u001b[39;00m\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/crewai_tools/tools/docx_search_tool/docx_search_tool.py:32\u001b[0m, in \u001b[0;36mDOCXSearchTool.__init__\u001b[0;34m(self, docx, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, docx: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m docx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(docx)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/crewai_tools/tools/rag/rag_tool.py:47\u001b[0m, in \u001b[0;36mRagTool._set_default_adapter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39membedchain\u001b[39;00m \u001b[39mimport\u001b[39;00m App\n\u001b[1;32m     45\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcrewai_tools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madapters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membedchain_adapter\u001b[39;00m \u001b[39mimport\u001b[39;00m EmbedchainAdapter\n\u001b[0;32m---> 47\u001b[0m     app \u001b[39m=\u001b[39m App\u001b[39m.\u001b[39;49mfrom_config(config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39melse\u001b[39;00m App()\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39m=\u001b[39m EmbedchainAdapter(\n\u001b[1;32m     49\u001b[0m         embedchain_app\u001b[39m=\u001b[39mapp, summarize\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummarize\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/embedchain/app.py:363\u001b[0m, in \u001b[0;36mApp.from_config\u001b[0;34m(cls, config_path, config, auto_deploy, yaml_path)\u001b[0m\n\u001b[1;32m    360\u001b[0m     config_data \u001b[39m=\u001b[39m {}\n\u001b[1;32m    362\u001b[0m \u001b[39m# Validate the config\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m validate_config(config_data)\n\u001b[1;32m    365\u001b[0m app_config_data \u001b[39m=\u001b[39m config_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mapp\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m, {})\n\u001b[1;32m    366\u001b[0m vector_db_config_data \u001b[39m=\u001b[39m config_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvectordb\u001b[39m\u001b[39m\"\u001b[39m, {})\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/embedchain/utils/misc.py:503\u001b[0m, in \u001b[0;36mvalidate_config\u001b[0;34m(config_data)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_config\u001b[39m(config_data):\n\u001b[1;32m    383\u001b[0m     schema \u001b[39m=\u001b[39m Schema(\n\u001b[1;32m    384\u001b[0m         {\n\u001b[1;32m    385\u001b[0m             Optional(\u001b[39m\"\u001b[39m\u001b[39mapp\u001b[39m\u001b[39m\"\u001b[39m): {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m         }\n\u001b[1;32m    501\u001b[0m     )\n\u001b[0;32m--> 503\u001b[0m     \u001b[39mreturn\u001b[39;00m schema\u001b[39m.\u001b[39;49mvalidate(config_data)\n",
      "File \u001b[0;32m/home/nfs/CDC/pcx5/.local/lib/python3.10/site-packages/schema.py:409\u001b[0m, in \u001b[0;36mSchema.validate\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m error:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m nkey\n\u001b[1;32m    408\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepend_schema_name(k)\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m SchemaError([message] \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39mautos, [e\u001b[39m.\u001b[39mformat(data) \u001b[39mif\u001b[39;00m e \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m] \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39merrors)\n\u001b[1;32m    410\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     new[nkey] \u001b[39m=\u001b[39m nvalue\n",
      "\u001b[0;31mSchemaError\u001b[0m: Key 'llm' error:\nAzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f66a7b0ea40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f66a7b40c10>, openai_api_key=SecretStr('**********'), openai_proxy='', azure_endpoint='https://edav-openai-pilot-east2.openai.azure.com/', deployment_name='edav-chatapp-share-gpt4-32k-tpm25kplus-v0613-dfilter', openai_api_version='2023-05-15', openai_api_type='azure') should be instance of 'dict'"
     ]
    }
   ],
   "source": [
    "submission_tool = DOCXSearchTool(\n",
    "    config=dict(\n",
    "        llm=dict(\n",
    "            provider=\"azure_openai\", # or google, openai, anthropic, llama2, ...\n",
    "            config=dict(\n",
    "                model=\"gpt-4-32k\",\n",
    "                # temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider=\"azure_openai\", # or openai, ollama, ...\n",
    "            config=dict(\n",
    "                model=\"text-embedding-ada-002\",\n",
    "                #task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    docx='resources/Nigeria HIV CBS Protocol_v3.4_27062022_PHIS3_clean.docx'\n",
    ")\n",
    "\n",
    "#submission = submission_tool(docx='resources/Nigeria HIV CBS Protocol_v3.4_27062022_PHIS3_clean.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up the agents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission_tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m policy_and_responsibilities_agent \u001b[39m=\u001b[39m Agent(\n\u001b[1;32m      2\u001b[0m   role\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPolicies and reponsibilities grader\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m   goal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExtract page number and text supporting a policy.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m   backstory\u001b[39m=\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mYou are knowledgeable about the development of protocols.\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m  You will check if the protocol has written policies, processes, and procedures for security breaches and training for all staff members with access to confidential data.\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m  You will look for data security policies define the roles and access levels of all persons with authorized access to confidential public health data and the procedures for accessing data securely.\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m  Protocol has a data sharing plan that includes intent and scope, methods that will be used to share data, steps that will be taken to ensure confidentiality and security of shared data, confidentiality agreements, and how shared data will be used, and published. In addition, protocol ensures that public health information, if released, is only for purposes related to public health, except where required by law. Protocol describes standards for any sharing data using appropriate secure methods.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m  Protocol describes who owns the data collected and how data collected will be retained or destroyed.\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m   llm \u001b[39m=\u001b[39m azure_llm,\n\u001b[1;32m     11\u001b[0m   verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m   allow_delegation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m---> 13\u001b[0m   tools\u001b[39m=\u001b[39m[submission_tool]\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submission_tool' is not defined"
     ]
    }
   ],
   "source": [
    "policy_and_responsibilities_agent = Agent(\n",
    "  role='Policies and reponsibilities grader',\n",
    "  goal='Extract page number and text supporting a policy.',\n",
    "  backstory=\"\"\"You are knowledgeable about the development of protocols.\n",
    "  You will check if the protocol has written policies, processes, and procedures for security breaches and training for all staff members with access to confidential data.\n",
    "  You will look for data security policies define the roles and access levels of all persons with authorized access to confidential public health data and the procedures for accessing data securely.\n",
    "  Protocol has a data sharing plan that includes intent and scope, methods that will be used to share data, steps that will be taken to ensure confidentiality and security of shared data, confidentiality agreements, and how shared data will be used, and published. In addition, protocol ensures that public health information, if released, is only for purposes related to public health, except where required by law. Protocol describes standards for any sharing data using appropriate secure methods.\n",
    "  Protocol describes who owns the data collected and how data collected will be retained or destroyed.\n",
    "  \"\"\",\n",
    "  llm = azure_llm,\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[submission_tool]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add their tasks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Task(\n",
    "  description=\"\"\"Check if there written policies and procedures to protect the privacy and security of personally identifiable data.\"\"\",\n",
    "  expected_output=\"Page number and quotation(s). If none found, return N/A for both page number and quotation\",\n",
    "  agent=policy_and_responsibilities_agent\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Check if policies and procedures be reviewed by all staff members with authorized access to confidential individual-level data.\"\"\",\n",
    "  expected_output=\"Page number and quotation(s). If none found, return N/A for both page number and quotation\",\n",
    "  agent=policy_and_responsibilities_agent\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will instantiate the crew of agents to evaulate the submission..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "  agents=[policy_and_responsibilities_agent, policy_and_responsibilities_agent],\n",
    "  tasks=[task1, task2],\n",
    "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can make your crew work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff()\n",
    "\n",
    "print(\"######################\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
